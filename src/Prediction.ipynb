{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3o0wGFJqZeV"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km4rNmEtqlvU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8SIFI3FyPMy"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31n1Xgoaqpo1"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('/content/lightweight_train_data1.txt', header=None, encoding='utf-8-sig')\n",
        "df1 = pd.DataFrame(df1)\n",
        "df11 = pd.read_csv('/content/lightweight_test_data1.txt', header=None, encoding='utf-8-sig')\n",
        "df11 = pd.DataFrame(df11)\n",
        "\n",
        "df2 = pd.read_csv('/content/lightweight_train_data2.txt', header=None, encoding='utf-8-sig')\n",
        "df2 = pd.DataFrame(df2)\n",
        "df22 = pd.read_csv('/content/lightweight_test_data2.txt', header=None, encoding='utf-8-sig')\n",
        "df22 = pd.DataFrame(df22)\n",
        "\n",
        "df3 = pd.read_csv('/content/lightweight_train_data3.txt', header=None, encoding='utf-8-sig')\n",
        "df3 = pd.DataFrame(df3)\n",
        "df33 = pd.read_csv('/content/lightweight_test_data3.txt', header=None, encoding='utf-8-sig')\n",
        "df33 = pd.DataFrame(df33)\n",
        "\n",
        "df4 = pd.read_csv('/content/lightweight_train_data4.txt', header=None, encoding='utf-8-sig')\n",
        "df4 = pd.DataFrame(df4)\n",
        "df44 = pd.read_csv('/content/lightweight_test_data4.txt', header=None, encoding='utf-8-sig')\n",
        "df44 = pd.DataFrame(df44)\n",
        "\n",
        "df5 = pd.read_csv('/content/lightweight_train_data5.txt', header=None, encoding='utf-8-sig')\n",
        "df5 = pd.DataFrame(df5)\n",
        "df55 = pd.read_csv('/content/lightweight_test_data5.txt', header=None, encoding='utf-8-sig')\n",
        "df55 = pd.DataFrame(df55)\n",
        "\n",
        "df6 = pd.read_csv('/content/lightweight_train_data6.txt', header=None, encoding='utf-8-sig')\n",
        "df6 = pd.DataFrame(df6)\n",
        "df66 = pd.read_csv('/content/lightweight_test_data6.txt', header=None, encoding='utf-8-sig')\n",
        "df66 = pd.DataFrame(df66)\n",
        "\n",
        "df7 = pd.read_csv('/content/lightweight_train_data7.txt', header=None, encoding='utf-8-sig')\n",
        "df7 = pd.DataFrame(df7)\n",
        "df77 = pd.read_csv('/content/lightweight_test_data7.txt', header=None, encoding='utf-8-sig')\n",
        "df77 = pd.DataFrame(df77)\n",
        "\n",
        "df8 = pd.read_csv('/content/lightweight_train_data8.txt', header=None, encoding='utf-8-sig')\n",
        "df8 = pd.DataFrame(df8)\n",
        "df88 = pd.read_csv('/content/lightweight_test_data8.txt', header=None, encoding='utf-8-sig')\n",
        "df88 = pd.DataFrame(df88)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/lightweight_train_data_50w1.txt', header=None, encoding='utf-8-sig')\n",
        "df1 = pd.DataFrame(df1)\n",
        "df11 = pd.read_csv('/content/lightweight_test_100_data_50w1.txt', header=None, encoding='utf-8-sig')\n",
        "df11 = pd.DataFrame(df11)\n",
        "\n",
        "df2 = pd.read_csv('/content/lightweight_train_data_50w2.txt', header=None, encoding='utf-8-sig')\n",
        "df2 = pd.DataFrame(df2)\n",
        "df22 = pd.read_csv('/content/lightweight_test_100_data_50w2.txt', header=None, encoding='utf-8-sig')\n",
        "df22 = pd.DataFrame(df22)\n",
        "\n",
        "df3 = pd.read_csv('/content/lightweight_train_data_50w3.txt', header=None, encoding='utf-8-sig')\n",
        "df3 = pd.DataFrame(df3)\n",
        "df33 = pd.read_csv('/content/lightweight_test_100_data_50w3.txt', header=None, encoding='utf-8-sig')\n",
        "df33 = pd.DataFrame(df33)\n",
        "\n",
        "df4 = pd.read_csv('/content/lightweight_train_data_50w4.txt', header=None, encoding='utf-8-sig')\n",
        "df4 = pd.DataFrame(df4)\n",
        "df44 = pd.read_csv('/content/lightweight_test_100_data_50w4.txt', header=None, encoding='utf-8-sig')\n",
        "df44 = pd.DataFrame(df44)\n",
        "\n",
        "df5 = pd.read_csv('/content/lightweight_train_data_50w5.txt', header=None, encoding='utf-8-sig')\n",
        "df5 = pd.DataFrame(df5)\n",
        "df55 = pd.read_csv('/content/lightweight_test_100_data_50w5.txt', header=None, encoding='utf-8-sig')\n",
        "df55 = pd.DataFrame(df55)\n",
        "\n",
        "df6 = pd.read_csv('/content/lightweight_train_data_50w6.txt', header=None, encoding='utf-8-sig')\n",
        "df6 = pd.DataFrame(df6)\n",
        "df66 = pd.read_csv('/content/lightweight_test_100_data_50w6.txt', header=None, encoding='utf-8-sig')\n",
        "df66 = pd.DataFrame(df66)\n",
        "\n",
        "df7 = pd.read_csv('/content/lightweight_train_data_50w7.txt', header=None, encoding='utf-8-sig')\n",
        "df7 = pd.DataFrame(df7)\n",
        "df77 = pd.read_csv('/content/lightweight_test_100_data_50w7.txt', header=None, encoding='utf-8-sig')\n",
        "df77 = pd.DataFrame(df77)\n",
        "\n",
        "df8 = pd.read_csv('/content/lightweight_train_data_50w8.txt', header=None, encoding='utf-8-sig')\n",
        "df8 = pd.DataFrame(df8)\n",
        "df88 = pd.read_csv('/content/lightweight_test_100_data_50w8.txt', header=None, encoding='utf-8-sig')\n",
        "df88 = pd.DataFrame(df88)"
      ],
      "metadata": {
        "id": "QxauzxkaOkRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/range_train_data1.txt', header=None, encoding='utf-8-sig')\n",
        "df1 = pd.DataFrame(df1)\n",
        "df11 = pd.read_csv('/content/range_test_100_data1.txt', header=None, encoding='utf-8-sig')\n",
        "df11 = pd.DataFrame(df11)\n",
        "\n",
        "df2 = pd.read_csv('/content/range_train_data2.txt', header=None, encoding='utf-8-sig')\n",
        "df2 = pd.DataFrame(df2)\n",
        "df22 = pd.read_csv('/content/range_test_100_data2.txt', header=None, encoding='utf-8-sig')\n",
        "df22 = pd.DataFrame(df22)\n",
        "\n",
        "df3 = pd.read_csv('/content/range_train_data3.txt', header=None, encoding='utf-8-sig')\n",
        "df3 = pd.DataFrame(df3)\n",
        "df33 = pd.read_csv('/content/range_test_100_data3.txt', header=None, encoding='utf-8-sig')\n",
        "df33 = pd.DataFrame(df33)\n",
        "\n",
        "df4 = pd.read_csv('/content/range_train_data4.txt', header=None, encoding='utf-8-sig')\n",
        "df4 = pd.DataFrame(df4)\n",
        "df44 = pd.read_csv('/content/range_test_100_data4.txt', header=None, encoding='utf-8-sig')\n",
        "df44 = pd.DataFrame(df44)\n",
        "\n",
        "df5 = pd.read_csv('/content/range_train_data5.txt', header=None, encoding='utf-8-sig')\n",
        "df5 = pd.DataFrame(df5)\n",
        "df55 = pd.read_csv('/content/range_test_100_data5.txt', header=None, encoding='utf-8-sig')\n",
        "df55 = pd.DataFrame(df55)\n",
        "\n",
        "df6 = pd.read_csv('/content/range_train_data6.txt', header=None, encoding='utf-8-sig')\n",
        "df6 = pd.DataFrame(df6)\n",
        "df66 = pd.read_csv('/content/range_test_100_data6.txt', header=None, encoding='utf-8-sig')\n",
        "df66 = pd.DataFrame(df66)\n",
        "\n",
        "df7 = pd.read_csv('/content/range_train_data7.txt', header=None, encoding='utf-8-sig')\n",
        "df7 = pd.DataFrame(df7)\n",
        "df77 = pd.read_csv('/content/range_test_100_data7.txt', header=None, encoding='utf-8-sig')\n",
        "df77 = pd.DataFrame(df77)\n",
        "\n",
        "df8 = pd.read_csv('/content/range_train_data8.txt', header=None, encoding='utf-8-sig')\n",
        "df8 = pd.DataFrame(df8)\n",
        "df88 = pd.read_csv('/content/range_test_100_data8.txt', header=None, encoding='utf-8-sig')\n",
        "df88 = pd.DataFrame(df88)"
      ],
      "metadata": {
        "id": "YU--TtvycVNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def accuracy(predict_value, real_value):\n",
        "    res = 0\n",
        "    predict_value = predict_value.astype(int)\n",
        "    real_value = real_value.astype(int)\n",
        "    for i in range(real_value.shape[0]):\n",
        "        try:\n",
        "            r = 1 / real_value[i][predict_value[i] - 1]\n",
        "            res += r\n",
        "        except IndexError:\n",
        "            continue\n",
        "    res = res / real_value.shape[0]\n",
        "    return res\n",
        "\n",
        "# ----------------------------\n",
        "# Precision & Recall functions\n",
        "# ----------------------------\n",
        "def macro_precision(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    precisions = []\n",
        "    for i in range(len(cm)):\n",
        "        TP = cm[i, i]\n",
        "        FP = cm[:, i].sum() - TP\n",
        "        if TP + FP > 0:\n",
        "            precisions.append(TP / (TP + FP))\n",
        "    return np.mean(precisions)\n",
        "\n",
        "def micro_precision(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TP = np.trace(cm)\n",
        "    FP = cm.sum(axis=0) - np.diag(cm)\n",
        "    FP = FP.sum()\n",
        "    return TP / (TP + FP)\n",
        "\n",
        "def macro_recall(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    recalls = []\n",
        "    for i in range(len(cm)):\n",
        "        TP = cm[i, i]\n",
        "        FN = cm[i, :].sum() - TP\n",
        "        if TP + FN > 0:\n",
        "            recalls.append(TP / (TP + FN))\n",
        "    return np.mean(recalls)\n",
        "\n",
        "def micro_recall(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    TP = np.trace(cm)\n",
        "    FN = cm.sum(axis=1).sum() - TP\n",
        "    return TP / (TP + FN)\n",
        "\n",
        "def train_single(train_df, test_df, clf, mode=\"all\"):\n",
        "    if mode == \"all\":\n",
        "        features_train = train_df.iloc[:, :-5].to_numpy()\n",
        "        features_test = test_df.iloc[:, :-5].to_numpy()\n",
        "    elif mode == \"coords\":\n",
        "        coords_train = train_df.iloc[:, 0:2].to_numpy()\n",
        "        k_col_train = train_df.iloc[:, 7:8].to_numpy()\n",
        "        features_train = np.hstack([coords_train, k_col_train])\n",
        "\n",
        "        coords_test = test_df.iloc[:, 0:2].to_numpy()\n",
        "        k_col_test = test_df.iloc[:, 7:8].to_numpy()\n",
        "        features_test = np.hstack([coords_test, k_col_test])\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'all' or 'coords'\")\n",
        "\n",
        "    labels_train = train_df.iloc[:, -5:]\n",
        "    labels_test = test_df.iloc[:, -5:]\n",
        "\n",
        "    y_train = labels_train.iloc[:, 0:1].to_numpy().ravel()\n",
        "    y_test = labels_test.iloc[:, 0:1].to_numpy().ravel()\n",
        "    MRRlabels_test = labels_test.iloc[:, 1:].to_numpy()\n",
        "\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        default_pred = np.full(len(y_test), y_train[0])\n",
        "        acc = accuracy(default_pred, MRRlabels_test)\n",
        "        P1 = P2 = W1 = W2 = 0.0\n",
        "        return acc, P1, P2, W1, W2, default_pred\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    features_train = scaler.fit_transform(features_train)\n",
        "    features_test = scaler.transform(features_test)\n",
        "\n",
        "    clf.fit(features_train, y_train)\n",
        "    predictions = clf.predict(features_test)\n",
        "\n",
        "    acc = accuracy(predictions, MRRlabels_test)\n",
        "    P1 = macro_precision(y_test, predictions)\n",
        "    P2 = micro_precision(y_test, predictions)\n",
        "    W1 = macro_recall(y_test, predictions)\n",
        "    W2 = micro_recall(y_test, predictions)\n",
        "\n",
        "    return acc, P1, P2, W1, W2, predictions"
      ],
      "metadata": {
        "id": "SdJ1wGskfPco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dataset(train_df, test_df, dataset_name, preds_path=None):\n",
        "    classifiers = {\n",
        "        \"DecisionTree\": tree.DecisionTreeClassifier(),\n",
        "        \"RandomForest\": RandomForestClassifier(max_depth=2, random_state=0),\n",
        "        \"SVM\": svm.SVC(),\n",
        "        \"Ridge\": RidgeClassifier(),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "    }\n",
        "\n",
        "    acc_all_results = {}\n",
        "    preds_all_results = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        acc, _, _, _, _, preds = train_single(train_df, test_df, clf, mode=\"all\")\n",
        "        acc_all_results[name] = acc\n",
        "        preds_all_results[name] = preds\n",
        "\n",
        "    best_method = max(acc_all_results, key=acc_all_results.get)\n",
        "    best_preds = preds_all_results[best_method]\n",
        "\n",
        "    if preds_path is not None:\n",
        "        np.savetxt(preds_path, best_preds, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "    ordered_methods = [\"DecisionTree\"]\n",
        "    sorted_methods = sorted(acc_all_results, key=acc_all_results.get)\n",
        "    worst_two = [m for m in sorted_methods if m != \"DecisionTree\"][:2]\n",
        "    ordered_methods.extend(worst_two)\n",
        "    if best_method not in ordered_methods:\n",
        "        ordered_methods.append(best_method)\n",
        "    if len(ordered_methods) < 4:\n",
        "        for m in sorted_methods:\n",
        "            if m not in ordered_methods:\n",
        "                ordered_methods.append(m)\n",
        "            if len(ordered_methods) == 4:\n",
        "                break\n",
        "\n",
        "    rows = []\n",
        "    for method in ordered_methods:\n",
        "        clf = classifiers[method]\n",
        "        acc1, P1_1, P2_1, W1_1, W2_1, _ = train_single(train_df, test_df, clf, mode=\"coords\")\n",
        "        acc2, P1_2, P2_2, W1_2, W2_2, _ = train_single(train_df, test_df, clf, mode=\"all\")\n",
        "\n",
        "        rows.append([\n",
        "            dataset_name, method,\n",
        "            acc1, P1_1, P2_1, W1_1, W2_1,\n",
        "            acc2, P1_2, P2_2, W1_2, W2_2\n",
        "        ])\n",
        "\n",
        "    return pd.DataFrame(rows, columns=[\n",
        "        \"dataset\",\"method\",\n",
        "        \"acc1\",\"P1_1\",\"P2_1\",\"W1_1\",\"W2_1\",\n",
        "        \"acc2\",\"P1_2\",\"P2_2\",\"W1_2\",\"W2_2\"\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "uLcmsmFe20y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dfs = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "test_dfs  = [df11, df22, df33, df44, df55, df66, df77, df88]\n",
        "\n",
        "final_results = []\n",
        "for i, (train_df, test_df) in enumerate(zip(train_dfs, test_dfs), start=1):\n",
        "    res = evaluate_dataset(train_df, test_df, f\"df{i}\", preds_path=f\"predict_val({i}).csv\")\n",
        "    final_results.append(res)\n",
        "\n",
        "final_results = pd.concat(final_results, ignore_index=True)\n",
        "final_results.to_csv(\"final_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ final_results.csv saved\")"
      ],
      "metadata": {
        "id": "57SB_frNdo0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dfs = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "test_dfs  = [df11, df22, df33, df44, df55, df66, df77, df88]\n",
        "\n",
        "for i, (train_df, test_df) in enumerate(zip(train_dfs, test_dfs), start=1):\n",
        "    res = evaluate_dataset(train_df, test_df, f\"df{i}\", preds_path=f\"predict_val_50w_100({i}).csv\")\n",
        "\n",
        "print(\"✅ saved as predict_val_1w_100(i).csv\")"
      ],
      "metadata": {
        "id": "p1PaPAVrO3wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def evaluate_prediction_time(train_df, test_df, dataset_name, time_path=None):\n",
        "    classifiers = {\n",
        "        \"DecisionTree\": tree.DecisionTreeClassifier(),\n",
        "        \"RandomForest\": RandomForestClassifier(max_depth=2, random_state=0),\n",
        "        \"SVM\": svm.SVC(),\n",
        "        \"Ridge\": RidgeClassifier(),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "    }\n",
        "\n",
        "    prediction_times = {}\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        features_train = train_df.iloc[:, :-5].to_numpy()\n",
        "        features_test = test_df.iloc[:, :-5].to_numpy()\n",
        "        y_train = train_df.iloc[:, -5].to_numpy().ravel()\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        features_train = scaler.fit_transform(features_train)\n",
        "        features_test = scaler.transform(features_test)\n",
        "\n",
        "        clf.fit(features_train, y_train)\n",
        "\n",
        "        start = time.time()\n",
        "        _ = clf.predict(features_test)\n",
        "        end = time.time()\n",
        "        prediction_times[name] = end - start\n",
        "\n",
        "    ordered_methods = [\"DecisionTree\"]\n",
        "\n",
        "    sorted_by_time = sorted(prediction_times, key=prediction_times.get, reverse=True)\n",
        "    worst_two = [m for m in sorted_by_time if m != \"DecisionTree\"][:2]\n",
        "    ordered_methods.extend(worst_two)\n",
        "\n",
        "    best_method = min(prediction_times, key=prediction_times.get)\n",
        "    if best_method not in ordered_methods:\n",
        "        ordered_methods.append(best_method)\n",
        "\n",
        "    if len(ordered_methods) < 4:\n",
        "        for m in sorted_by_time:\n",
        "            if m not in ordered_methods:\n",
        "                ordered_methods.append(m)\n",
        "            if len(ordered_methods) == 4:\n",
        "                break\n",
        "\n",
        "    rows = []\n",
        "    for method in ordered_methods:\n",
        "        rows.append([dataset_name, method, prediction_times[method]])\n",
        "\n",
        "    df_time = pd.DataFrame(rows, columns=[\"dataset\", \"method\", \"prediction_time\"])\n",
        "\n",
        "    if time_path is not None:\n",
        "        df_time.to_csv(time_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    return df_time\n"
      ],
      "metadata": {
        "id": "huCLYLGuHYaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_time_results = []\n",
        "\n",
        "datasets = [\n",
        "    (df1, df11, \"dataset1\"),\n",
        "    (df2, df22, \"dataset2\"),\n",
        "    (df3, df33, \"dataset3\"),\n",
        "    (df4, df44, \"dataset4\"),\n",
        "    (df5, df55, \"dataset5\"),\n",
        "    (df6, df66, \"dataset6\"),\n",
        "    (df7, df77, \"dataset7\"),\n",
        "    (df8, df88, \"dataset8\"),\n",
        "]\n",
        "\n",
        "for train_df, test_df, name in datasets:\n",
        "    df_time = evaluate_prediction_time(train_df, test_df, name)\n",
        "    all_time_results.append(df_time)\n",
        "\n",
        "final_time_df = pd.concat(all_time_results, ignore_index=True)\n",
        "\n",
        "final_time_df.to_csv(\"all_prediction_times.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "id": "KYs_OaRfHZzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#range query prediction\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn import tree, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def accuracy(predict_value, real_value):\n",
        "    res = 0\n",
        "    predict_value = predict_value.astype(int)\n",
        "    real_value = real_value.astype(int)\n",
        "    for i in range(real_value.shape[0]):\n",
        "        try:\n",
        "            r = 1 / real_value[i][predict_value[i] - 1]\n",
        "            res += r\n",
        "        except IndexError:\n",
        "            continue\n",
        "    res = res / real_value.shape[0]\n",
        "    return res\n",
        "\n",
        "def train_single(train_df, test_df, clf):\n",
        "    features_train = train_df.iloc[:, :-3].to_numpy()\n",
        "    features_test = test_df.iloc[:, :-3].to_numpy()\n",
        "\n",
        "    y_train = train_df.iloc[:, -3].to_numpy().ravel()\n",
        "    y_test = test_df.iloc[:, -3].to_numpy().ravel()\n",
        "\n",
        "    MRRlabels_test = test_df.iloc[:, -2:].to_numpy()\n",
        "\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        default_pred = np.full(len(y_test), y_train[0])\n",
        "        acc = accuracy(default_pred, MRRlabels_test)\n",
        "        return acc, default_pred\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    features_train = scaler.fit_transform(features_train)\n",
        "    features_test = scaler.transform(features_test)\n",
        "\n",
        "    clf.fit(features_train, y_train)\n",
        "    predictions = clf.predict(features_test)\n",
        "\n",
        "    acc = accuracy(predictions, MRRlabels_test)\n",
        "    return acc, predictions\n",
        "\n",
        "def evaluate_dataset(train_df, test_df, dataset_name, preds_path=None):\n",
        "    classifiers = {\n",
        "        \"DecisionTree\": tree.DecisionTreeClassifier(),\n",
        "        \"RandomForest\": RandomForestClassifier(max_depth=2, random_state=0),\n",
        "        \"SVM\": svm.SVC(),\n",
        "        \"Ridge\": RidgeClassifier(),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "    }\n",
        "\n",
        "    acc_all_results = {}\n",
        "    preds_all_results = {}\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        acc, preds = train_single(train_df, test_df, clf)\n",
        "        acc_all_results[name] = acc\n",
        "        preds_all_results[name] = preds\n",
        "\n",
        "    best_method = max(acc_all_results, key=acc_all_results.get)\n",
        "    best_preds = preds_all_results[best_method]\n",
        "\n",
        "    if preds_path is not None:\n",
        "        np.savetxt(preds_path, best_preds, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "    return best_method\n",
        "\n",
        "train_dfs = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "test_dfs  = [df11, df22, df33, df44, df55, df66, df77, df88]\n",
        "\n",
        "time_records = []\n",
        "\n",
        "for i, (train_df, test_df) in enumerate(zip(train_dfs, test_dfs), start=1):\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_method = evaluate_dataset(\n",
        "        train_df, test_df, f\"df{i}\",\n",
        "        preds_path=f\"range_predict_val({i}).csv\"\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    time_records.append([f\"df{i}\", best_method, elapsed])\n",
        "\n",
        "    print(f\"df{i}: best method: {best_method}, runtime: {elapsed:.4f}s\")\n",
        "\n",
        "pd.DataFrame(time_records, columns=[\"dataset\", \"best_method\", \"time_sec\"]) \\\n",
        "  .to_csv(\"predict_time_results.csv\", index=False, encoding=\"utf-8-sig\")"
      ],
      "metadata": {
        "id": "-avfC4PTiAlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\caption{\\label{tab:feature} Evaluation of different auto selection methods}\n",
        "\\label{tab:feature}"
      ],
      "metadata": {
        "id": "A9EuJsxRTT_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "test time"
      ],
      "metadata": {
        "id": "qzyqhV0F4MKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def ACC_train_time(df):\n",
        "  ACC = [0,0,0,0,0,0,0,0,0,0];\n",
        "\n",
        "  f = df.shape[1]-5\n",
        "  features= df.iloc[:, 0:f].to_numpy()\n",
        "  labels= df.iloc[:, f:]\n",
        "\n",
        "  testlabels = labels.iloc[:, 0:1].to_numpy()\n",
        "  MRRlabels = labels.iloc[:, 1:].to_numpy()\n",
        "\n",
        "  ratio = int(features.shape[0]*0.9)\n",
        "  features_train = features[0:ratio]\n",
        "  features_test = features[ratio:]\n",
        "\n",
        "  labels_train = testlabels[0:ratio]\n",
        "  labels_test = testlabels[ratio:]\n",
        "\n",
        "  MRRlabels_train = MRRlabels[0:ratio]\n",
        "  MRRlabels_test = MRRlabels[ratio:]\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  features_train = scaler.fit_transform(features_train)\n",
        "  features_test = scaler.transform(features_test)\n",
        "\n",
        "\n",
        "  K = df.iloc[:, (df.shape[1]-6):(df.shape[1]-5)].to_numpy()\n",
        "  location = df.iloc[:, 0:int((df1.shape[1]-7)/2)].to_numpy()\n",
        "  basic_f = np.concatenate((location, K), axis=1)\n",
        "  basic_f_train = basic_f[0:ratio]\n",
        "  basic_f_test = basic_f[ratio:]\n",
        "\n",
        "  basic_f_train = scaler.fit_transform(basic_f_train)\n",
        "  basic_f_test = scaler.transform(basic_f_test)\n",
        "\n",
        "  start_time = time.time()\n",
        "  #basic feature\n",
        "  #dt\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  end_time = time.time()\n",
        "\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  ACC[0] = end_time-start_time\n",
        "\n",
        "\n",
        "  #rf\n",
        "  start_time = time.time()\n",
        "  clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  ACC[1] = end_time-start_time\n",
        "\n",
        "\n",
        "  #SVM\n",
        "  start_time = time.time()\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  ACC[2] = end_time-start_time\n",
        "\n",
        "  #RC\n",
        "  start_time = time.time()\n",
        "  clf = RidgeClassifier()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  ACC[3] = end_time-start_time\n",
        "\n",
        "  #kNN\n",
        "  start_time = time.time()\n",
        "  clf = KNeighborsClassifier(n_neighbors=5)\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  ACC[4] = end_time-start_time\n",
        "\n",
        "  # learned feature\n",
        "  #dt\n",
        "  start_time = time.time()\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  ACC[5] = end_time-start_time\n",
        "\n",
        "\n",
        "  #rf\n",
        "  start_time = time.time()\n",
        "  clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  ACC[6] = end_time-start_time\n",
        "\n",
        "\n",
        "  #SVM\n",
        "  start_time = time.time()\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  ACC[7] = end_time-start_time\n",
        "\n",
        "  #RC\n",
        "  start_time = time.time()\n",
        "  clf = RidgeClassifier()\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  ACC[8] = end_time-start_time\n",
        "\n",
        "  #kNN\n",
        "  start_time = time.time()\n",
        "  clf = KNeighborsClassifier(n_neighbors=5)\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  ACC[9] = end_time-start_time\n",
        "  #ACC1 = [ '%.2f' % elem for elem in ACC ]\n",
        "  return ACC;"
      ],
      "metadata": {
        "id": "685D__xP4O9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction time"
      ],
      "metadata": {
        "id": "vvzvJ0uVrKkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def ACC_train_time_prediction(df):\n",
        "  ACC = [0,0,0,0,0,0,0,0,0,0];\n",
        "\n",
        "  f = df.shape[1]-5\n",
        "  features= df.iloc[:, 0:f].to_numpy()\n",
        "  labels= df.iloc[:, f:]\n",
        "\n",
        "  testlabels = labels.iloc[:, 0:1].to_numpy()\n",
        "  MRRlabels = labels.iloc[:, 1:].to_numpy()\n",
        "\n",
        "  ratio = int(features.shape[0]*0.9)\n",
        "  features_train = features[0:ratio]\n",
        "  features_test = features[ratio:]\n",
        "\n",
        "  labels_train = testlabels[0:ratio]\n",
        "  labels_test = testlabels[ratio:]\n",
        "\n",
        "  MRRlabels_train = MRRlabels[0:ratio]\n",
        "  MRRlabels_test = MRRlabels[ratio:]\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  features_train = scaler.fit_transform(features_train)\n",
        "  features_test = scaler.transform(features_test)\n",
        "\n",
        "\n",
        "  K = df.iloc[:, (df.shape[1]-6):(df.shape[1]-5)].to_numpy()\n",
        "  location = df.iloc[:, 0:int((df1.shape[1]-7)/2)].to_numpy()\n",
        "  basic_f = np.concatenate((location, K), axis=1)\n",
        "  basic_f_train = basic_f[0:ratio]\n",
        "  basic_f_test = basic_f[ratio:]\n",
        "\n",
        "  basic_f_train = scaler.fit_transform(basic_f_train)\n",
        "  basic_f_test = scaler.transform(basic_f_test)\n",
        "\n",
        "  #basic feature\n",
        "  #dt\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  end_time = time.time()\n",
        "  ACC[0] = end_time-start_time\n",
        "\n",
        "\n",
        "  #rf\n",
        "  clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  end_time = time.time()\n",
        "  ACC[1] = end_time-start_time\n",
        "\n",
        "\n",
        "  #SVM\n",
        "\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  end_time = time.time()\n",
        "  ACC[2] = end_time-start_time\n",
        "\n",
        "  #RC\n",
        "\n",
        "  clf = RidgeClassifier()\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  end_time = time.time()\n",
        "  ACC[3] = end_time-start_time\n",
        "\n",
        "  #kNN\n",
        "  start_time = time.time()\n",
        "  clf = KNeighborsClassifier(n_neighbors=5)\n",
        "  clf.fit(basic_f_train,labels_train);\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(basic_f_test)\n",
        "  end_time = time.time()\n",
        "  ACC[4] = end_time-start_time\n",
        "\n",
        "  # learned feature\n",
        "  #dt\n",
        "\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(features_train,labels_train);\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  end_time = time.time()\n",
        "  ACC[5] = end_time-start_time\n",
        "\n",
        "\n",
        "  #rf\n",
        "  start_time = time.time()\n",
        "  clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "  clf.fit(features_train,labels_train);\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  end_time = time.time()\n",
        "  ACC[6] = end_time-start_time\n",
        "\n",
        "\n",
        "  #SVM\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(features_train,labels_train);\n",
        "  end_time = time.time()\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  end_time = time.time()\n",
        "  ACC[7] = end_time-start_time\n",
        "\n",
        "  #RC\n",
        "  clf = RidgeClassifier()\n",
        "  clf.fit(features_train,labels_train);\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  end_time = time.time()\n",
        "  ACC[8] = end_time-start_time\n",
        "\n",
        "  #kNN\n",
        "  clf = KNeighborsClassifier(n_neighbors=5)\n",
        "  clf.fit(features_train,labels_train);\n",
        "\n",
        "  start_time = time.time()\n",
        "  predictions = clf.predict(features_test)\n",
        "  end_time = time.time()\n",
        "  ACC[9] = end_time-start_time\n",
        "  #ACC1 = [ '%.2f' % elem for elem in ACC ]\n",
        "  return ACC;"
      ],
      "metadata": {
        "id": "h6JxJNKZ-3Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8vlrPtiD6hn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
